{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_EagerExecution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "v8YKBNVJDM34",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as p\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-eI5daMVI4sg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Eager Execution\n",
        "\n",
        "TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. To follow along with this guide, run the code samples below in an interactive python interpreter.\n",
        "\n",
        "Eager execution is a flexible machine learning platform for research and experimentation, providing:\n",
        "\n",
        "*    An intuitive interface—Structure your code naturally and use Python data structures. Quickly iterate on small models and small data.\n",
        "*    Easier debugging—Call ops directly to inspect running models and test changes. Use standard Python debugging tools for immediate error reporting.\n",
        "*    Natural control flow—Use Python control flow instead of graph control flow, simplifying the specification of dynamic models.\n",
        "\n",
        "Eager execution supports most TensorFlow operations and GPU acceleration.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Enabling eager execution changes how TensorFlow operations behave — now they immediately evaluate and return their values to Python. tf.Tensor objects reference concrete values instead of symbolic handles to nodes in a computational graph. **Since there isn't a computational graph to build and run later in a session, it's easy to inspect results using print() or a debugger. Evaluating, printing, and checking tensor values does not break the flow for computing gradients.**\n",
        "\n",
        "Eager execution works nicely with NumPy. NumPy operations accept tf.Tensor arguments. TensorFlow math operations convert Python objects and NumPy arrays to tf.Tensor objects. The tf.Tensor.numpy method returns the object's value as a NumPy ndarray."
      ]
    },
    {
      "metadata": {
        "id": "k6FWT9mzKQUG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "waJlrC0nKFNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ]
    },
    {
      "metadata": {
        "id": "ymQtAiqgKWpY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V7fnsWZpKaVm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check if using**"
      ]
    },
    {
      "metadata": {
        "id": "l-X7g07YJT4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a28f154-15a0-41e7-ae59-6440c11dc52b"
      },
      "cell_type": "code",
      "source": [
        "tf.executing_eagerly() "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "y7RVFFr7Kjdh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Examples**"
      ]
    },
    {
      "metadata": {
        "id": "yfhOeQAlKWsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f73b0c49-1bdb-4ca5-8386-6f3eb735caad"
      },
      "cell_type": "code",
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(\"hello, {}\".format(m)) # No need of using tf.Session!!"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello, [[4.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qmabbvnAKt_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0f870b25-729b-4a30-cf51-441c387b8fa4"
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "print(a)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QNFmuK7NK3Uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0998c905-116d-40f6-db73-68356b4b1553"
      },
      "cell_type": "code",
      "source": [
        "# Broadcasting support\n",
        "b = tf.add(a, 1)\n",
        "print(b)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_6OzDmy5K3X0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3ebc4374-bd8e-4e29-9832-fa38ca4d8c76"
      },
      "cell_type": "code",
      "source": [
        "# Operator overloading is supported\n",
        "print(a * b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  6]\n",
            " [12 20]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dl-fWetqKuBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ce8e22f4-21bd-4b98-9fba-7677c2c43e34"
      },
      "cell_type": "code",
      "source": [
        "# Use NumPy values!!\n",
        "c = np.multiply(a, b)\n",
        "print(c)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  6]\n",
            " [12 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OaGSLDIiK-x1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "68107a81-0ed3-44d3-e451-a7f2d2d93a8f"
      },
      "cell_type": "code",
      "source": [
        "# Obtain numpy value from a tensor:\n",
        "print(a.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nybk8pwzLIER",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**You can even write a tf FizzBuzz**"
      ]
    },
    {
      "metadata": {
        "id": "OcRNpZo7KuEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "9a6eab37-b253-4b6c-bce3-18006ab65cd3"
      },
      "cell_type": "code",
      "source": [
        "def fizzbuzz(max_num):\n",
        "    counter = tf.constant(0)\n",
        "    max_num = tf.convert_to_tensor(max_num)\n",
        "    for num in range(1, max_num.numpy()+1):\n",
        "        num = tf.constant(num)\n",
        "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "            print('FizzBuzz')\n",
        "        elif int(num % 3) == 0:\n",
        "            print('Fizz')\n",
        "        elif int(num % 5) == 0:\n",
        "            print('Buzz')\n",
        "        else:\n",
        "            print(num.numpy())\n",
        "        counter += 1\n",
        "        \n",
        "fizzbuzz(24)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "Fizz\n",
            "4\n",
            "Buzz\n",
            "Fizz\n",
            "7\n",
            "8\n",
            "Fizz\n",
            "Buzz\n",
            "11\n",
            "Fizz\n",
            "13\n",
            "14\n",
            "FizzBuzz\n",
            "16\n",
            "17\n",
            "Fizz\n",
            "19\n",
            "Buzz\n",
            "Fizz\n",
            "22\n",
            "23\n",
            "Fizz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fRpGC7aLyyL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Computing gradients**\n",
        "\n",
        "During eager execution, use [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to trace operations for computing gradients later."
      ]
    },
    {
      "metadata": {
        "id": "AlWARjMzLy5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6f9af8c-8980-4640-baad-2e1cb6ae5552"
      },
      "cell_type": "code",
      "source": [
        "w = tf.Variable([[1.0]])\n",
        "with tf.GradientTape() as tape:\n",
        "    loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(grad)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Msg4__BEMgCC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Trainable variables are automatically watched. Tensors can be manually watched by invoking the **watch** method on this context manager."
      ]
    },
    {
      "metadata": {
        "id": "EPluFdqWMZwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85d23a6e-b455-42c9-c0d1-dad7c1ff38e9"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape() as g:\n",
        "    g.watch(x)\n",
        "    y = x * x\n",
        "    \n",
        "dy_dx = g.gradient(y, x)\n",
        "print(dy_dx)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tgZp-JUDMp-Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GradientTapes can be nested to compute higher-order derivatives. For example,"
      ]
    },
    {
      "metadata": {
        "id": "oNhq6kXeMZ4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d395763c-ab1b-40be-e0af-3ecdf4c3ad6f"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape() as g:\n",
        "    g.watch(x)\n",
        "    with tf.GradientTape() as gg:\n",
        "        gg.watch(x)\n",
        "        y = x * x\n",
        "    \n",
        "    dy_dx = gg.gradient(y, x)\n",
        "d2y_dx2 = g.gradient(dy_dx, x)\n",
        "\n",
        "print(dy_dx)\n",
        "print(d2y_dx2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-cpffbAENF8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2YGjUBcJTHh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Performance\n",
        "\n",
        "Some models may experience increased overhead with eager execution enabled. Performance improvements are ongoing.\n",
        "\n",
        "For compute-heavy models, such as ResNet50 training on a GPU, eager execution performance is comparable to graph execution. But this gap grows larger for models with less computation and there is work to be done for optimizing hot code paths for models with lots of small operations.\n",
        "\n",
        "While eager execution makes development and debugging more interactive, TensorFlow graph execution has advantages for distributed training, performance optimizations, and production deployment. However, **writing graph code can feel different than writing regular Python code and more difficult to debug.**"
      ]
    },
    {
      "metadata": {
        "id": "Aesn6PrWIv63",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}