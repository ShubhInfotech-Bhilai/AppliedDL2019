{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FashionMNIST_TPU","version":"0.3.2","provenance":[{"file_id":"https://github.com/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb","timestamp":1559154860071}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N6ZDpd9XzFeN"},"source":["##### Copyright 2018 The TensorFlow Hub Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"KUu4vOt5zI9d","colab":{}},"source":["# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# =============================================================================="],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"edfbxDDh2AEs"},"source":["## Fashion MNIST with Keras and TPUs"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RNo1Vfghpa8j"},"source":["## Overview\n","\n","In this example, you can try out using tf.keras and Cloud TPUs to train a model on the fashion MNIST dataset. The model trains for 20 epochs on Cloud TPU and takes approximately 3 minutes to run.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QrprJD-R-410"},"source":["## Instructions"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_I0RdnOSkNmi"},"source":["<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n","\n","1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n","1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5eEM-XOvURoU"},"source":["TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Lvo0t7XVIkWZ"},"source":["## Data, model, and training"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MICrRv8rmXVq"},"source":["Begin by downloading the fashion MNIST dataset using `tf.keras.datasets`, as shown below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zo-Yk6LFGfSf","colab":{}},"source":["import os\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","# add empty color dimension\n","x_train = np.expand_dims(x_train, -1)\n","x_test = np.expand_dims(x_test, -1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Hgc2FZKVMx15"},"source":["### Define the model\n","\n","The following example uses a standard conv-net that has 3 layers with drop-out and batch normalization between each layer."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W7gMbs70GxA7","colab":{}},"source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(256))\n","model.add(tf.keras.layers.Activation('elu'))\n","model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(10))\n","model.add(tf.keras.layers.Activation('softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHkvl5nQFPQh","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xLeZATVaNAnE"},"source":["### Train on the TPU\n","\n","To begin training, construct the model on the TPU and then compile it.\n","\n","You have to [pass your keras model to tpu](https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/keras_to_tpu_model), with a propper [strategy](https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUDistributionStrategy) and [TPU resolver.](https://www.tensorflow.org/api_docs/python/tf/contrib/cluster_resolver/TPUClusterResolver).\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pWEYmd_hIWg8","colab":{}},"source":["tpu_model = ###"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwVGbXnYEGGa","colab_type":"text"},"source":["You can use a generator function and [`fit_generator`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit_generator) to train the model.  Alternately, you can pass in `x_train` and `y_train` to [`tpu_model.fit()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit)."]},{"cell_type":"code","metadata":{"id":"TUi9tQnW_qid","colab_type":"code","colab":{}},"source":["###"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ESL6ltQTMm05"},"source":["### Check the results (inference)\n","\n","Now that you are done training, see how well the model can predict fashion categories!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SaYPv_aKId2d","colab":{}},"source":["LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n","\n","\n","cpu_model = tpu_model.sync_to_cpu()\n","\n","from matplotlib import pyplot\n","%matplotlib inline\n","\n","def plot_predictions(images, predictions):\n","    n = images.shape[0]\n","    nc = int(np.ceil(n / 4))\n","    f, axes = pyplot.subplots(nc, 4)\n","    for i in range(nc * 4):\n","        y = i // 4\n","        x = i % 4\n","        axes[x, y].axis('off')\n","\n","        label = LABEL_NAMES[np.argmax(predictions[i])]\n","        confidence = np.max(predictions[i])\n","        if i > n:\n","            continue\n","        axes[x, y].imshow(images[i])\n","        axes[x, y].text(0.5, 0.5, label + '\\n%.3f' % confidence, fontsize=14)\n","\n","    pyplot.gcf().set_size_inches(8, 8)  \n","\n","plot_predictions(np.squeeze(x_test[:16]), \n","                 tpu_model.predict(x_test[:16]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2a5cGsSTEBQD"},"source":["## What's next\n","\n","* Learn about [Cloud TPUs](https://cloud.google.com/tpu/docs) that Google designed and optimized specifically to speed up and scale up ML workloads for training and inference and to enable ML engineers and researchers to iterate more quickly.\n","* Explore the range of [Cloud TPU tutorials and Colabs](https://cloud.google.com/tpu/docs/tutorials) to find other examples that can be used when implementing your ML project.\n","\n","On Google Cloud Platform, in addition to GPUs and TPUs available on pre-configured [deep learning VMs](https://cloud.google.com/deep-learning-vm/),  you will find [AutoML](https://cloud.google.com/automl/)*(beta)* for training custom models without writing code and [Cloud ML Engine](https://cloud.google.com/ml-engine/docs/) which will allows you to run parallel trainings and hyperparameter tuning of your custom models on powerful distributed hardware.\n"]}]}